{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+CL4eU52lsgFe0MaRBy18",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hectorcamachoz/Regresion_logistica_validacion_cruzada/blob/main/A2_1_594557.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresion logistica y validacion cruzada\n",
        "\n",
        "En este ejercicio se utilizara la misma base de datos que en el proyecto 1. Inteligencia Artificial, que se puede encontrar en los repositorios de Github."
      ],
      "metadata": {
        "id": "NTYhYkz0A6rw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Se importara la base de datos y se limpiara. (Estos pasos ya se habian realizado en Proyecto 1. Inteligencia Artificial, si quieres conocer el porque de estos pasos, te invito a pasar al repositorio del proyecto). Lo que se medira es si se rentan mas de 2500 bicis al dia o no, ya que al ser verdadero se considera que fue un buen dia de rentas. Por lo tanto se agregara una variable que se llame 'renta_del_dia', esta variable sera 1, si se rentan mas de 2500 o 2500, y 0 si se rentan menos de 2500. Al hacer este cambio, se debe de eliminar la variable cnt."
      ],
      "metadata": {
        "id": "82kqmJ5QHk2p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nctgFbPg_m6_",
        "outputId": "10bf550a-6608-45f8-fb2a-6785014bda4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "renta_del_dia\n",
            "1    587\n",
            "0    144\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('day.csv')\n",
        "df = df.drop('instant', axis=1)\n",
        "df = df.drop('dteday', axis= 1)\n",
        "df = df.drop('mnth', axis = 1)\n",
        "df = df.drop('weekday', axis=1)\n",
        "df = pd.get_dummies(df, columns=['season', 'weathersit'],drop_first=False, dtype = int)\n",
        "df = df.drop('atemp', axis = 1)\n",
        "\n",
        "df = df.drop('casual', axis = 1)\n",
        "df = df.drop('registered', axis = 1)\n",
        "\n",
        "renta_del_dia = []\n",
        "\n",
        "for i in df['cnt']:\n",
        "    if i >= 2500:\n",
        "        renta_del_dia.append(1)\n",
        "    else:\n",
        "        renta_del_dia.append(0)\n",
        "df = pd.concat([df, pd.Series(renta_del_dia, name='renta_del_dia')], axis=1)\n",
        "df = df.drop('cnt', axis = 1)\n",
        "df.head()\n",
        "\n",
        "print(df.renta_del_dia.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Se separaran los datos de forma que el 80% sera utilizado para el entrenamiento y el 20% para la validacion del modelo. Ademas, se le agregara un parametro a la funcion de train_test_split de sklearn, llamado stratify, esta se encarga de realizar una division de datos balanceada para mi variable de salida. Tambien realizare una seleccion de caracteristicas para eliminar cualquier variable que no tenga importancia con mi variable de salida."
      ],
      "metadata": {
        "id": "ERzbosZWIH8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop('renta_del_dia', axis = 1)\n",
        "y = df['renta_del_dia']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 42)\n",
        "\n",
        "print(\"Distribución en y:\\n\", y.value_counts(normalize=True))\n",
        "print(\"\\nDistribución en y_train:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"\\nDistribución en y_test:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "md_seleccion = LogisticRegression()\n",
        "\n",
        "sfs = SFS(md_seleccion, k_features= 'best',forward=True, floating = True, scoring='r2',cv=5)\n",
        "sfs.fit(x_train, y_train)\n",
        "\n",
        "selected_features = list(sfs.k_feature_names_)\n",
        "print('\\nCaracteristicas seleccionadas: ', selected_features)\n",
        "print('R2 score: ', sfs.k_score_)\n",
        "\n",
        "x_train = x_train[selected_features]\n",
        "x_test = x_test[selected_features]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZB2-iLBOlNG",
        "outputId": "06d005bc-36ba-4543-ca96-5662fb870d56"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución en y:\n",
            " renta_del_dia\n",
            "1    0.80301\n",
            "0    0.19699\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Distribución en y_train:\n",
            " renta_del_dia\n",
            "1    0.803082\n",
            "0    0.196918\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Distribución en y_test:\n",
            " renta_del_dia\n",
            "1    0.802721\n",
            "0    0.197279\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Caracteristicas seleccionadas:  ['yr', 'holiday', 'temp', 'windspeed', 'season_4', 'weathersit_1', 'weathersit_2', 'weathersit_3']\n",
            "R2 score:  0.6427163220037202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. A continuacion, se utilizara la tecnica de StratifiedKFold de la libreria sklearn, en el cual se medira el accuracy de un modelo a partir de estos datos. Esta funcion la encontre utilizando ChatGpt."
      ],
      "metadata": {
        "id": "6RVSJKqoPKoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "x_np = x_train.to_numpy()\n",
        "y_np = y_train.to_numpy()\n",
        "i = 1\n",
        "# Este es un split, dentro del split\n",
        "for train_index, test_index in skf.split(x_np, y_np):\n",
        "    X_train_2, X_test_2 = x_train.iloc[train_index], x_train.iloc[test_index]\n",
        "    y_train_2, y_test_2 = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train_2, y_train_2)\n",
        "\n",
        "    y_pred = model.predict(X_test_2)\n",
        "    accuracy = accuracy_score(y_test_2, y_pred)\n",
        "    print(f\"Fold\",[i],\" Accuracy:\", round(accuracy,3))\n",
        "    i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxxwf8RKQuzf",
        "outputId": "8726c7e4-b7a9-48a3-931f-9475c213a3f6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold [1]  Accuracy: 0.932\n",
            "Fold [2]  Accuracy: 0.949\n",
            "Fold [3]  Accuracy: 0.923\n",
            "Fold [4]  Accuracy: 0.94\n",
            "Fold [5]  Accuracy: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Se realizara un modelo con todos los datos de entrenamiento, utilizando una regresion logistica multivariable, se generara un vector de probabilidades para los datos de prueba, y a su vez se generara una matriz de confusion junto con la exactitud, sesibilidad y especificidad del modelo ante 3 umbrales distintos.\n"
      ],
      "metadata": {
        "id": "o-4GH1vsYrv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_proba = model.predict_proba(x_test)[:,1]\n",
        "print('Vector de probabilidades: \\n', y_pred_proba)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN3YDG2RZPTy",
        "outputId": "deca9fa5-4b34-4427-9414-c5e919d0e05b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector de probabilidades: \n",
            " [0.97307128 0.78332976 0.87281921 0.87207874 0.90952057 0.99108153\n",
            " 0.51967726 0.99420998 0.99432558 0.95377888 0.24469244 0.92243512\n",
            " 0.94207494 0.95546545 0.85890633 0.99567519 0.12204888 0.96496454\n",
            " 0.84859031 0.98920007 0.96855367 0.97489266 0.93881245 0.9786864\n",
            " 0.81019122 0.95834788 0.98439435 0.94821352 0.93941236 0.96820052\n",
            " 0.99604152 0.97275367 0.54609326 0.99401908 0.88404274 0.40900548\n",
            " 0.993266   0.86401455 0.98524079 0.91557834 0.89963857 0.64069633\n",
            " 0.47899903 0.9395254  0.42321858 0.95466186 0.68255838 0.98857359\n",
            " 0.97344132 0.9885826  0.32917474 0.9540649  0.95910886 0.66481097\n",
            " 0.98727842 0.95361217 0.66438845 0.40849829 0.96991874 0.96501171\n",
            " 0.76141285 0.94098946 0.89905402 0.99515541 0.41159186 0.97021408\n",
            " 0.74679549 0.9424684  0.97963436 0.98944399 0.97737438 0.97039355\n",
            " 0.90323072 0.98204895 0.98327514 0.57764375 0.97292659 0.98991174\n",
            " 0.99095536 0.47780378 0.99556751 0.99284087 0.49891362 0.99461441\n",
            " 0.98045181 0.96399162 0.63647319 0.84898933 0.96801892 0.8472984\n",
            " 0.94234522 0.91906099 0.97860291 0.84338323 0.99164152 0.93240196\n",
            " 0.99219743 0.46863264 0.80933355 0.99335526 0.9011485  0.99035875\n",
            " 0.68092993 0.22128809 0.97031202 0.97279585 0.73620432 0.79819371\n",
            " 0.97430081 0.99318151 0.90610823 0.75673433 0.97311428 0.99588139\n",
            " 0.32479916 0.49647551 0.53954116 0.751664   0.97577789 0.83245915\n",
            " 0.8186257  0.95767311 0.8682081  0.96462605 0.97597165 0.96731053\n",
            " 0.12440726 0.99406511 0.80995943 0.78934035 0.99529001 0.5551519\n",
            " 0.95281885 0.84738877 0.8825109  0.9318509  0.22692991 0.92211582\n",
            " 0.84851833 0.96205799 0.94073105 0.91334919 0.92864076 0.47160199\n",
            " 0.99422236 0.91909131 0.99309876]\n"
          ]
        }
      ]
    }
  ]
}